# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JIs-cH3r5RJgVQG4FdhRmOqyi4oUZbEK

DBS Coding Camp
- Zuhair Nashif Abdurrohim
- 1301223102
- MC012D5Y1127

# Import
"""

# Library untuk visualisasi
import seaborn as sns
import matplotlib.pyplot as plt

# File handling dan sistem
import os
import zipfile
from google.colab import files

# Data processing
import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Model ML
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor

# Evaluasi model
from sklearn.metrics import mean_squared_error
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

"""# Data Loading"""

# Upload file kaggle.json
files.upload()

# Setup untuk API kaggle
os.makedirs("/root/.kaggle", exist_ok=True)
os.rename("kaggle.json", "/root/.kaggle/kaggle.json")
os.chmod("/root/.kaggle/kaggle.json", 600)

# Download dataset dari Kaggle
!kaggle datasets download -d nelgiriyewithana/apple-quality

# Ekstrak file ZIP
with zipfile.ZipFile("apple-quality.zip", 'r') as zip_ref:
    zip_ref.extractall("apple_quality")

# Import dataset ke DataFrame dan tampilkan
df = pd.read_csv("apple_quality/apple_quality.csv")
df.head()

"""# EDA : Exploratory Data Analysis"""

# Menampilkan informasi data
df.info()

# Merubah tipe data Acidity dari object -> float64
df['Acidity'] = pd.to_numeric(df['Acidity'], errors='coerce')
df.info()

# Menampilkan deskripsi data
df.describe()

# Menampilkan ukuran data
df.shape

"""### Atasi Missing Value"""

# Check apakah ada data null atau NaN
df.isnull().sum()

# Tampilkan data yang bernilai null atau NaN
df[df.isnull().any(axis=1)]

# Menghapus baris dengan data NaN
df = df.dropna()

df.shape

"""### Atasi Outlier"""

# Daftar kolom dengan tipe data numerik
numerical_features = ['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'Ripeness', 'Acidity']

# Menampilkan boxplot untuk setiap fitur numerical
fig, axes = plt.subplots(2, 4, figsize=(16, 8))
axes = axes.flatten()

for i, col in enumerate(numerical_features):
    sns.boxplot(x=df[col], ax=axes[i])
    axes[i].set_title(col)

for i in range(len(numerical_features), len(axes)):
    fig.delaxes(axes[i])

plt.tight_layout()
plt.show()

# Atasi outlier dengan menggantinya dengan nilai batas atas / bawah IQR (Winsorizing)
def winsorize_iqr(df, column):
  Q1 = df[column].quantile(0.25)
  Q3 = df[column].quantile(0.75)
  IQR = Q3 - Q1
  lower_bound = Q1 - 1.5 * IQR
  upper_bound = Q3 + 1.5 * IQR

  df[column] = df[column].apply(
      lambda x: lower_bound if x < lower_bound else upper_bound if x > upper_bound else x
  )
  return df

df = winsorize_iqr(df, 'Size')
df = winsorize_iqr(df, 'Weight')
df = winsorize_iqr(df, 'Sweetness')
df = winsorize_iqr(df, 'Crunchiness')
df = winsorize_iqr(df, 'Juiciness')
df = winsorize_iqr(df, 'Ripeness')
df = winsorize_iqr(df, 'Acidity')

# Tampilkan kembali boxplot setelah outlier diatasi
fig, axes = plt.subplots(2, 4, figsize=(16, 8))
axes = axes.flatten()

for i, col in enumerate(numerical_features):
    sns.boxplot(x=df[col], ax=axes[i])
    axes[i].set_title(col)

for i in range(len(numerical_features), len(axes)):
    fig.delaxes(axes[i])

plt.tight_layout()
plt.show()

"""### Univariate Analysis"""

# Pembagian fitur berdasar tipenya
numerical_features = ['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'Ripeness', 'Acidity']
categorical_features = ['Quality']

# Melihat persebaran data Quality

feature = categorical_features[0];
count = df['Quality'].value_counts()
percent = 100*df['Quality'].value_counts(normalize=True)
df_quality = pd.DataFrame({'Jumlah':count, 'Persentase':percent.round(1)})
print(df_quality)
count.plot(kind='bar', title=feature);

# Melihat persebaran data untuk numerical features
df.hist(bins=50, figsize=(20,15))
plt.show()

"""### Multivariate Analysis"""

# Scatter plot untuk hubungan 2 numerical features
sns.pairplot(df, diag_kind = 'kde')

# Heatmap untuk hubungan 2 fitur
plt.figure(figsize=(10, 8))
correlation_matrix = df[numerical_features].corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title('Correlation Heatmap unutuk Numerical Features')

# Lakukan drop colom ID karena tidak digunakan
df = df.drop(['A_id'], axis=1)
df

"""# Data Preparation

### Encoding kategori
"""

# Melakukan encoding untuk kolom Quality dan menggantinya menjadi 1 dan 0
le = LabelEncoder()
mapping = {'good': 1, 'bad': 0}
df['Quality'] = le.fit_transform(df['Quality'].map(mapping))
df

"""### Split Data"""

# Melakukan split data 80:20 persiapan pembuatan model
from sklearn.model_selection import train_test_split

X = df.drop(['Quality'], axis=1)
y = df['Quality']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Tampilkan jumlah data
print(len(X))
print(len(X_train))
print(len(X_test))

"""### Standarisasi"""

# Lakukan standarisasi
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])

# Transform dan simpan hasilnya ke kolom yang sama
X_train[numerical_features] = scaler.transform(X_train[numerical_features])
X_train[numerical_features].describe().round(4)

"""# Modeling"""

# Membuat dataframe untuk menyimpan MSE
models = pd.DataFrame(index=['train_mse', 'test_mse'], columns=['KNN', 'Random Forest'])

"""### KNN"""

# Membuat model KNN
knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)

models.loc['train_mse', 'knn'] = mean_squared_error(y_pred=knn.predict(X_train), y_true=y_train)

"""### Random Forest"""

# Membuat model Random Forest
RF = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse', 'randomforest'] = mean_squared_error(y_pred=RF.predict(X_test), y_true=y_test)

"""# Evaluation

### MSE
"""

X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

# Hitung dan tampilkan MSE
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN', 'Random Forest'])

model_dict = {'KNN': knn, 'Random Forest': RF}

for name, model in model_dict.items():
  mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))
  mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))

mse

"""### Accuracy, Precision, Recall, F1-Score"""

# Matriks evaluasi
evaluation_metrics = pd.DataFrame(columns=['Accuracy', 'Precision', 'Recall', 'F1-Score'], index=['KNN', 'Random Forest'])

# KNN
knn_predictions = knn.predict(X_test)
knn_predictions = (knn_predictions > 0.5).astype(int)
evaluation_metrics.loc['KNN', 'Accuracy'] = accuracy_score(y_test, knn_predictions)
evaluation_metrics.loc['KNN', 'Precision'] = precision_score(y_test, knn_predictions)
evaluation_metrics.loc['KNN', 'Recall'] = recall_score(y_test, knn_predictions)
evaluation_metrics.loc['KNN', 'F1-Score'] = f1_score(y_test, knn_predictions)


# Random Forest
rf_predictions = RF.predict(X_test)
rf_predictions = (rf_predictions > 0.5).astype(int)
evaluation_metrics.loc['Random Forest', 'Accuracy'] = accuracy_score(y_test, rf_predictions)
evaluation_metrics.loc['Random Forest', 'Precision'] = precision_score(y_test, rf_predictions)
evaluation_metrics.loc['Random Forest', 'Recall'] = recall_score(y_test, rf_predictions)
evaluation_metrics.loc['Random Forest', 'F1-Score'] = f1_score(y_test, rf_predictions)

evaluation_metrics

"""# Uji"""

# Uji dengan data terakhir dalam df
last_apple = df.tail(1).copy()

X_last_apple = last_apple.drop('Quality', axis=1)
y_true = last_apple['Quality'].values[0]

X_last_apple.loc[:, numerical_features] = scaler.transform(X_last_apple[numerical_features])

knn_prediction = knn.predict(X_last_apple)[0]
rf_prediction = RF.predict(X_last_apple)[0]

print(f"Actual Quality: {y_true}")
print(f"KNN Prediction: {knn_prediction}")
print(f"Random Forest Prediction: {rf_prediction}")

print(f"KNN Rounded Prediction: {round(knn_prediction)}")
print(f"Random Forest Rounded Prediction: {round(rf_prediction)}")